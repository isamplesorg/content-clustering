{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ad6c3b",
   "metadata": {},
   "source": [
    "### Mine useful terms from different clusters\n",
    "### Datasets are downloadable from  https://mars.cyverse.org/data_dumps/GEOME.txt.zip\n",
    "\n",
    "#### replace GEOME with other relevant collection name to get the data set. \n",
    "\n",
    "#### Download, unzip, and put the .txt file in the appropriate folder according to the jupyter file\n",
    "\n",
    "\n",
    "#### Author: Hong Cui\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d085dec",
   "metadata": {},
   "source": [
    "### Obtain clusters and their informative terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae1c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fasttext # pip install fasttext-0.9.2-cp310-cp310-win_amd64.whl\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.cluster import Birch\n",
    "import fastcluster\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.options.display.max_rows = 4000\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "cores = min(1, cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# srcs = {\n",
    "#         \"GEOME\": ['record_colloquialName', 'record_scientificName','record_kingdom', 'record_phylum',\n",
    "#                   'record_subPhylum', 'record_order', 'record_infraOrder', 'record_superOrder',\n",
    "#                   'record_subOrder', 'record_class', 'record_subClass', 'record_infraClass', 'record_tribe', \n",
    "#                   'record_subTribe', 'record_superFamily', 'record_family', 'record_subFamily', 'record_genus',\n",
    "#                   'record_subGenus', 'record_specificEpithet', 'record_infraspecificEpithet', 'record_taxonRemarks', \n",
    "#                   'record_taxonRank', 'record_sex', 'record_preservative', 'record_fixative', 'record_relaxant', \n",
    "#                   'parent_fieldNotes','parent_locality', 'parent_verbatimLocality', 'parent_habitat', \n",
    "#                   'parent_microHabitat', 'record_morphospeciesDescription', 'record_lifeStage'], \n",
    "#         \"OPENCONTEXT\":['Temporal Coverage_label', \n",
    "#              'Has taxonomic identifier_label','Has anatomical identification_label',\n",
    "#              'Consists of_label',  'Has type_label', 'item category', 'context label'], \n",
    "#         \"SMITHSONIAN\":[ 'scientificName', 'higherClassification', 'kingdom', 'phylum', 'class', 'order', \n",
    "#                        'family', 'genus', 'subgenus', 'specificEpithet', 'infraspecificEpithet', 'sex',\n",
    "#                        'lifeStage', 'habitat', 'preparations', 'waterBody', 'occurrenceRemarks','locality'], \n",
    "#         \"SESAR\":['description_supplementMetadata_geologicalAge','description_collectionMethod', \n",
    "#                  'description_material',  'description_sampleType', \n",
    "#                  'description_supplementMetadata_classificationComment', 'description_description', \n",
    "#                  'description_supplementMetadata_purpose', 'description_collectionMethodDescr',\n",
    "#                  'description_supplementMetadata_primaryLocationType', \n",
    "#                  'description_supplementMetadata_geologicalUnit', 'description_supplementMetadata_locality',\n",
    "#                  'description_supplementMetadata_localityDescription', 'description_supplementMetadata_fieldName']\n",
    "#        }\n",
    "\n",
    "# srcs = {\n",
    "#         \"GEOME\": ['record_scientificName', 'parent_locality'], \n",
    "#         \"OPENCONTEXT\":['Has taxonomic identifier_label','Has anatomical identification_label',\n",
    "#              'Consists of_label',  'Has type_label', 'item category'], \n",
    "#         \"SMITHSONIAN\":[ 'scientificName', 'higherClassification', 'waterBody', 'locality'], \n",
    "#         \"SESAR\":['description_material',  'description_sampleType', \n",
    "#                  'description_supplementMetadata_purpose', \n",
    "#                  'description_supplementMetadata_primaryLocationType', \n",
    "#                  'description_supplementMetadata_geologicalUnit', 'description_supplementMetadata_locality',\n",
    "#                  'description_supplementMetadata_fieldName']\n",
    "#        }\n",
    "\n",
    "srcs = {\n",
    "        \"GEOME\": ['parent_habitat', 'parent_microHabitat'], \n",
    "#         \"OPENCONTEXT\": ['Consists of_label']     \n",
    "#\"OPENCONTEXT\":['Consists of_label',  'Has type_label'] \n",
    "         \"SMITHSONIAN\":[ 'habitat'], \n",
    "#         \"SESAR\":['description_material',  'description_sampleType', \n",
    "#                  'description_supplementMetadata_purpose', \n",
    "#                  'description_supplementMetadata_primaryLocationType', \n",
    "#                  'description_supplementMetadata_fieldName']\n",
    "       }\n",
    "\n",
    "# srcs = {\n",
    "#         \"GEOME\": ['record_scientificName', 'parent_locality'], \n",
    "#         \"OPENCONTEXT\":['Has taxonomic identifier_label','Has anatomical identification_label',\n",
    "#              'Consists of_label',  'Has type_label', 'item category'], \n",
    "#         \"SMITHSONIAN\":[ 'scientificName', 'higherClassification', 'waterBody', 'locality'], \n",
    "#         \"SESAR\":['description_material',  'description_sampleType', \n",
    "#                  'description_supplementMetadata_purpose', \n",
    "#                  'description_supplementMetadata_primaryLocationType', \n",
    "#                  'description_supplementMetadata_fieldName']\n",
    "#       }\n",
    "\n",
    "srcids = {\n",
    "        \"GEOME\": 'record_bcid', \n",
    "        #\"OPENCONTEXT\": 'citation uri', \n",
    "        \"SMITHSONIAN\":'occurrenceID', \n",
    "        #\"SESAR\":'igsn'\n",
    "       }\n",
    "\n",
    "#srcnames = [\"GEOME\", \"OPENCONTEXT\", \"SMITHSONIAN\", \"SESAR\"]\n",
    "\n",
    "srcnames = [\"GEOME\", \"SMITHSONIAN\"]\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc577f5e",
   "metadata": {},
   "source": [
    "### frequency counts of the entries in one collection and one field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba1c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCounts2CSV (c, cname, threshold):\n",
    "    th = pd.DataFrame(columns=[cname, \"count\"])\n",
    "    for i in c.index:\n",
    "        if c[i] >= threshold:\n",
    "            th  =  th.append({cname:i,  \"count\":c[i]}, ignore_index = True)\n",
    "    th.to_csv(\"counts \"+ cname+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8200570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src=\"OPENCONTEXT\"\n",
    "data = pd.read_csv('data/'+src+'.txt',sep='#', keep_default_na=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b22c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data['context label'].value_counts()\n",
    "# if contains greater than 4000 rows, so it cann't be displayed fully by default\n",
    "# print out entries in f one by one\n",
    "for r in a.index:\n",
    "    print(str(a[r]) +\" :\"+r)  #count: phrases\n",
    "   \n",
    "saveCounts2CSV(a, \"OC context\", 10)\n",
    "    \n",
    "\n",
    "b = data['Consists of_label'].value_counts()\n",
    "b\n",
    "saveCounts2CSV(b, \"OC consists\", 10)\n",
    "\n",
    "c = data['Has type_label'].value_counts()\n",
    "c\n",
    "saveCounts2CSV(c, \"OC type\", 10)\n",
    "\n",
    "\n",
    "d = data['item category'].value_counts()\n",
    "d\n",
    "saveCounts2CSV(d, \"OC item category\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d30867",
   "metadata": {},
   "outputs": [],
   "source": [
    "src=\"GEOME\"\n",
    "data = pd.read_csv('data/'+src+'.txt',sep='#', keep_default_na=False, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5591633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fuzzywuzzy import fuzz\n",
    "# from fuzzywuzzy import process\n",
    "\n",
    "# data.columns\n",
    "# #data[fuzz.ratio(data['parent_habitat'], 'arctostaphylos pungens')> 90]\n",
    "\n",
    "# #arctostaphylos pungens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb9ac30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = data['parent_habitat'].value_counts()\n",
    "e\n",
    "saveCounts2CSV(e, \"GEOME habitat\", 10)\n",
    "\n",
    "f = data['parent_microHabitat'].value_counts()\n",
    "f\n",
    "saveCounts2CSV(e, \"GEOME mircoHabitat\", 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f687145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(src):\n",
    "    id_property = srcids[src]\n",
    "    intrinsic_properties = srcs[src].copy()\n",
    "    print(src)\n",
    "    #print(id_property) \n",
    "    #print(intrinsic_properties)\n",
    "    data = pd.DataFrame()\n",
    "    data = pd.read_csv('data/'+src+'.txt',sep='#', keep_default_na=False, encoding='utf-8')\n",
    "    #print(data)\n",
    "    if not id_property:\n",
    "        data['id'] = range(0,data.shape[0]) #when no id field is supplied\n",
    "        id_property = 'id'\n",
    "    \n",
    "    #print(intrinsic_properties)\n",
    "    #print(id_property)\n",
    "    intrinsic_properties.append(id_property)\n",
    "    #print(intrinsic_properties)\n",
    "    data = data.filter(intrinsic_properties, axis=1)\n",
    "    #print(data.columns) \n",
    "    data = data.rename(columns={id_property:'id'})\n",
    "    data['src'] = src\n",
    "    #data['id'] = src+':'+data['id'].astype(str)\n",
    "    data['original']= ''\n",
    "\n",
    "    for p in intrinsic_properties:\n",
    "        if not p == id_property:\n",
    "            #print('property: '+p)\n",
    "            data['original'] = data[p].astype(str)+';'+data['original'] \n",
    "    #print(data)\n",
    "    data['original'] = data['original'].str.replace(r\";+\", \";\")\n",
    "    data = data.dropna(subset = ['original']).reset_index(drop=True)\n",
    "    data = data[['src', 'id', 'original']] #id + original\n",
    "    data.reset_index(inplace=True, drop=True)              \n",
    "    return data\n",
    "                                \n",
    "#test = getData(\"GEOME\")\n",
    "#print(test)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatherTerm(cframe, threshold):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df = 1, max_features=500, min_df=0, stop_words='english',\n",
    "                                  use_idf=True, ngram_range=(1, 3))\n",
    "    try:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(cframe['description'])\n",
    "        #print('tfidf_matrix')\n",
    "        #print(tfidf_matrix[0,2])\n",
    "        terms = tfidf_vectorizer.get_feature_names()\n",
    "        #print('terms')\n",
    "        #print(terms)\n",
    "        ordered_index = tfidf_matrix.toarray().argsort()[:, ::-1]\n",
    "        #print('ordered_index')\n",
    "        #print(ordered_index) \n",
    "\n",
    "        #print(\"threshold:\"+str(threshold))\n",
    "        #print(\"length of ordered index:\"+str(len(ordered_index)))\n",
    "        #print(\"# of clusters:\"+str(num_clusters))\n",
    "        allterms = []\n",
    "        for i in range(0, len(cframe)):\n",
    "            #print('i='+str(i))\n",
    "            n_terms = []\n",
    "            for ind in ordered_index[i,]: \n",
    "                #print('ind='+str(ind))\n",
    "                #print(ordered_index[i,])\n",
    "                if tfidf_matrix[i, ind] > threshold:\n",
    "                    n_terms.append(terms[ind]) \n",
    "            allterms.append(n_terms)\n",
    "        return allterms\n",
    "        \n",
    "    except ValueError:#no term obtained from tfidf when all records holds the same set of terms\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content_src = pd.DataFrame()\n",
    "\n",
    "data_list=[]\n",
    "data_list = Parallel(n_jobs=min(len(srcnames), cores), verbose=50)(delayed(getData)(src) for src in srcnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content_src = pd.concat(data_list, ignore_index=True)\n",
    "df_content_src['original_beforeclean'] = df_content_src['original']\n",
    "df_content_src.shape #5,833,656\n",
    "del data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17858c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "estopwords = stopwords.words('english')+[\"sample\", \"samples\", \"sampling\", \"sampled\", \"sample_id\", \"cm\"]\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(line):\n",
    "    if pd.isna(line):\n",
    "        return ''\n",
    "    else:\n",
    "        newline =''\n",
    "        for token1 in re.split(r'#+', line):\n",
    "            for token2 in token1.split():\n",
    "                token2 = token2.lower()\n",
    "                if token2.startswith('https://') or token2.startswith('http://') or re.match(\".*?\\d.*\", token2) or len(token2)<=2 or token2 in estopwords:\n",
    "                    next\n",
    "                else:\n",
    "                    token2 = re.sub(r'['+string.punctuation+']', ' ', token2)\n",
    "                    for token3 in re.split(r'[/<>. ]', token2):\n",
    "                        if len(token3)<=2 or token3 in estopwords:\n",
    "                            next\n",
    "                        else:\n",
    "                            newline = newline+' '+token3.strip()\n",
    "                        \n",
    "        return newline.strip()\n",
    "    \n",
    "    \n",
    "# line = \"Char WS-9513.01.06-b*\"\"#event.###[blank]/records:/[blank]  [ *found * {}: [and at https://wwww.applies.com/###12 cm. l.d. ###width 1dm ###rock>mineral>blue mineral###\"    \n",
    "# # line = '\"\"#\"\"#\"\"#\"\"#\"74\"#\"\"#\"\"#\"74\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"2020\"#\"\"#\"\"#\"University of Florida\"#\"\"#\"23.8361515\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"Alpheidae sp. 1\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"BOMAN_3342\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"Oman\"#\"\"#\"NSF_OMAN\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"OMAN_020A\"#\"\"#\"\"#\"\"#\"NSF_OMAN\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"1\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"57.9767976\"#\"\"#\"Event\"#\"\"#\"\"#\"\"#\"\"#\"Sample\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"in Pocillopora and Acropora rubble\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"Damanyat Islands, S of June Island\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"Abby Uehling\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"74\"#\"\"#\"Abby Uehling\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"Muscat Governorate\"#\"\"#\"\"#\"OMAN_020A\"#\"\"#\"Arthropoda\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"#\"\"'\n",
    "# # re.split(r'#+', line)\n",
    "# newline = clean(line)\n",
    "# newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12656d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "allplines_src = list()\n",
    "allplines_src = Parallel(n_jobs=cores)(delayed(clean)(line) for line in df_content_src['original'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16beef2a",
   "metadata": {},
   "source": [
    "### frequency counts of combined fields from one or more collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all fields selected are combined into 'original'\n",
    "df_content_src['original'] = allplines_src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2fc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in df_content_src['original']: \n",
    "    if 'arctostaphylos pungens' in text:\n",
    "        temp = df_content_src[df_content_src['original'] == text]['original_beforeclean']\n",
    "        for t in temp:\n",
    "            print(t)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8116fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df_content_src['original'].value_counts()\n",
    "g\n",
    "saveCounts2CSV(g, \"three habitats\", 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be569e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd42093",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"df_content_src.shape[0] before dropna:\"+str(df_content_src.shape[0])) \n",
    "df_content_src = df_content_src.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "df_content_src = df_content_src.dropna(how='any').reset_index(drop=True)\n",
    "print(\"df_content_src.shape[0] after dropna:\"+str(df_content_src.shape[0])) \n",
    "df_content_src.drop_duplicates(subset='original', ignore_index=True, inplace=True) #remove redundant rows\n",
    "print(\"df_content_src.shape[0] after deduplicationa:\"+str(df_content_src.shape[0])) \n",
    "pd.unique(df_content_src['src'])\n",
    "plines_src = df_content_src['original']\n",
    "\n",
    "#del allplines_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed83547",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model('data/cc.en.300.bin') #takes 7GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963275d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vlines_src = list() #records represented as vectors\n",
    "for pline in plines_src:\n",
    "    vlines_src.append(model.get_sentence_vector(pline))\n",
    "\n",
    "#normalize to unit vector\n",
    "vlines_src = normalize(vlines_src, axis=1)\n",
    "print(\"len(vlines_src):\")\n",
    "print(len(vlines_src))\n",
    "#del model #reclaim memory\n",
    "#print(vlines_src[0])\n",
    "#print(len(vlines_src)) \n",
    "\n",
    "\n",
    "#with open(\"vlines_src.all.fasttext\"+\".pkl\", 'wb') as outp:\n",
    "#    pickle.dump(vlines_src, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8523a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def birch(rep, vlines_src):\n",
    "    brc_src = Birch(branching_factor=20000, n_clusters=12, threshold=0.5) #n_clusters = None, meaning unlimited  \n",
    "    brc_src.fit(vlines_src)\n",
    "\n",
    "    labels_src = brc_src.predict(vlines_src)\n",
    "    df_src = pd.DataFrame({'src':df_content_src['src'], 'id':df_content_src['id'], 'birchcluster':labels_src, 'content':plines_src, 'original':df_content_src['original']}) \n",
    "\n",
    "    tab = df_src.groupby(['src','birchcluster']).size()\n",
    "    print(rep+\" source clusters:\")\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        #print(tab.unstack().transpose())\n",
    "        print(tab.transpose())\n",
    "\n",
    "    #with open(\"clusters.src.birch.\"+rep+\".pkl\", 'wb') as outp:\n",
    "     #   pickle.dump(df_src, outp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "  \n",
    "    return df_src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b3ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = 'fasttext'\n",
    "df = birch(rep, vlines_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d1e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"clusters.src.birch.\"+rep+\".pkl\", 'rb') as inp:\n",
    "#     df = pickle.load(inp)\n",
    "    \n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee91071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#produce terms from Birch clustering result\n",
    "\n",
    "frame = df[['birchcluster','content']]\n",
    "frame = frame.rename(columns={'birchcluster':'cluster', 'content':'description'})\n",
    "cframe =frame.groupby('cluster', as_index = False).agg({'description': ' '.join})\n",
    "terms = gatherTerm(cframe, 0.1)\n",
    "i=0\n",
    "for term in terms:\n",
    "    print('cluster '+ str(cframe.iloc[i]['cluster'])+':')\n",
    "    print(term)\n",
    "    i = i+1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e604b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## clustering of subclusters of BIRCH result with parallal programming\n",
    "\n",
    "from fastcluster import linkage_vector\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "\n",
    "#birchcluster_df: the input observation data (D=300xN)\n",
    "#birchcluster_number:  cluster number of birchcluster_df in BIRCH result \n",
    "#min_obs: minimal observations in birchcluster_df to run hierarichal clustering, must be >=2\n",
    "\n",
    "def h_clustering_fast(birchcluster_df, birchcluster_number, link_method, min_obs=2 ):\n",
    "    if len(birchcluster_df) < min_obs:\n",
    "        return [] \n",
    "    else:\n",
    "        linkage_matrix = fastcluster.linkage_vector(birchcluster_df, link_method) #single, complete, average, weighted, median, centroid, ward\n",
    "        return linkage_matrix\n",
    "    \n",
    "#result = h_clustering_fast(vlines[df.index[df['birchcluster']==0]], 0, 'ward', 20)\n",
    "#result\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#birchcluster_df: df holding the birchcluster observation content\n",
    "#birchcluster_number:  cluster number of birchcluster_df in BIRCH result \n",
    "#linkage_matrix: the linkage_matrix for the birchcluster\n",
    "#t: threshold to obtain clusters from hierarchical clustering for the specified criterion\n",
    "#criterion: criterion used to obtain clusters\n",
    "\n",
    "def obtain_h_clusters(birchcluster_df, birchcluster_number, linkage_matrix, t=10, criterion=\"maxclust\"):\n",
    "    if np.any(linkage_matrix):\n",
    "        clusters = fcluster(linkage_matrix, t, criterion=criterion) #distance, inconsistency\n",
    "        num_clusters = len(np.unique(clusters))\n",
    "        birchcluster_df = birchcluster_df.reset_index()\n",
    "        cresult = birchcluster_df[['index']]\n",
    "        cresult['hcluster']= clusters\n",
    "         \n",
    "        #index lines with clusters\n",
    "        records = {'description':df[df['birchcluster']==birchcluster_number].content, 'cluster':clusters, 'birchcluster':birchcluster_number}\n",
    "        frame = pd.DataFrame(records, columns=['description', 'cluster', 'birchcluster'])\n",
    "        cframe =frame.groupby('cluster', as_index = True).agg({'description': ' '.join})\n",
    "        return cresult\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "\n",
    "    \n",
    "#len(results)\n",
    "#16 empty\n",
    "#cresult = obtain_h_clusters(df[df['birchcluster']==3], 3, linkage_matrix=results[3], t=3 if df[df['birchcluster']==3].shape[0] < 100 else 10 , criterion=\"maxclust\")\n",
    "#cresult\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aa9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []        \n",
    "results = Parallel(n_jobs=8, verbose=1)(delayed(h_clustering_fast)(vlines_src[df.index[df['birchcluster']==c]], c, 'ward', 2)  for c in range(0, len(df.birchcluster.unique())))\n",
    "print(\"# of linkage matrices obtained: \"+str(len(results)))\n",
    "\n",
    "cresultlist = []\n",
    "for cresult in Parallel(n_jobs=8,verbose=1)(delayed(obtain_h_clusters)(df[df['birchcluster']==c], c, linkage_matrix=results[c], t=3 if df[df['birchcluster']==c].shape[0] < 100 else 10, criterion='maxclust') for c in range(0, len(df.birchcluster.unique()))):\n",
    "    cresultlist.append(cresult)\n",
    "\n",
    "\n",
    "combined = pd.DataFrame()\n",
    "#concat list of cresult row-wise\n",
    "for cresult in cresultlist:\n",
    "    combined = pd.concat([combined, cresult], ignore_index=True)\n",
    "        \n",
    "\n",
    "#print(combined)    \n",
    "combined.set_index('index', inplace=True)\n",
    "\n",
    "#df now holds all the results\n",
    "df = df.join(combined) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#produce terms from Birch + hierarchical clustering results\n",
    "\n",
    "df[\"cluster\"] = df[\"birchcluster\"].astype(str) +'-'+ df[\"hcluster\"].astype(str)\n",
    "frame = df[['cluster','content']]\n",
    "frame = frame.rename(columns={'content':'description'})\n",
    "cframe =frame.groupby('cluster', as_index = False).agg({'description': ' '.join})\n",
    "terms = gatherTerm(cframe, 0.1)\n",
    "i=0\n",
    "allterms = list()\n",
    "for term in terms:\n",
    "    print('cluster '+cframe.iloc[i]['cluster']+':')\n",
    "    print(term)\n",
    "    i = i+1\n",
    "    print()\n",
    "    allterms.extend(term)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33caa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(allterms)\n",
    "counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5c362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
